{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [\n",
    "    \"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\",\n",
    "    \"cont8\", \"cont9\", \"cont10\",\n",
    "]\n",
    "cat_features = [\n",
    "    \"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\",\n",
    "    \"cat8\", \"cat9\", \"cat10\", \"cat11\", \"cat12\", \"cat13\", \"cat14\", \"cat15\",\n",
    "    \"cat16\", \"cat17\", \"cat18\"\n",
    "]\n",
    "target = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import CatBoostEncoder, LeaveOneOutEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_cat_features = []\n",
    "lgb_cat_features = []\n",
    "cb_cat_features = []\n",
    "ridge_cat_features = []\n",
    "\n",
    "loo_features = []\n",
    "le_features = []\n",
    "\n",
    "def label_encode(train, test, column):\n",
    "    le = LabelEncoder()\n",
    "    new_feature = \"{}_le\".format(column)\n",
    "    le.fit(train[column].unique().tolist() + test[column].unique().tolist())\n",
    "    train[new_feature] = le.transform(train[column])\n",
    "    test[new_feature] = le.transform(test[column])\n",
    "    return new_feature\n",
    "\n",
    "def loo_encode(train, test, column):\n",
    "    loo = LeaveOneOutEncoder()\n",
    "    new_feature = \"{}_loo\".format(column)\n",
    "    loo.fit(train[column], train['target']) \n",
    "    train[new_feature] = loo.transform(train[column])\n",
    "    test[new_feature] = loo.transform(test[column])\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    loo_features.append(loo_encode(train, test, feature))\n",
    "    le_features.append(label_encode(train, test, feature))\n",
    "    \n",
    "xgb_cat_features.extend(loo_features)\n",
    "lgb_cat_features.extend(le_features)\n",
    "cb_cat_features.extend(cat_features)\n",
    "ridge_cat_features.extend(loo_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8983017846431489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8992752749691963\n",
      ": CB - ROC AUC Score = 0.8969627750077146\n",
      ": Ridge - ROC AUC Score = 0.8766369762926142\n",
      "\n",
      "--> Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8959564270898941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8965719305867795\n",
      ": CB - ROC AUC Score = 0.894896330360522\n",
      ": Ridge - ROC AUC Score = 0.8758266069616415\n",
      "\n",
      "--> Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8940539594014382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.895886292280639\n",
      ": CB - ROC AUC Score = 0.8927082989283495\n",
      ": Ridge - ROC AUC Score = 0.8728614118821589\n",
      "\n",
      "--> Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8942548198343717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8952394120091154\n",
      ": CB - ROC AUC Score = 0.8928892610593528\n",
      ": Ridge - ROC AUC Score = 0.8731456945335946\n",
      "\n",
      "--> Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8960471278527358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8971458428093266\n",
      ": CB - ROC AUC Score = 0.8952166205500075\n",
      ": Ridge - ROC AUC Score = 0.8777665458860092\n",
      "\n",
      "--> Fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.897114734236636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8982421838933615\n",
      ": CB - ROC AUC Score = 0.8961538779342406\n",
      ": Ridge - ROC AUC Score = 0.8768702891611878\n",
      "\n",
      "--> Fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8976791053175636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8990042825802195\n",
      ": CB - ROC AUC Score = 0.896403813617131\n",
      ": Ridge - ROC AUC Score = 0.875852497009206\n",
      "\n",
      "--> Fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8973837778816753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8978977897671531\n",
      ": CB - ROC AUC Score = 0.8967892426412977\n",
      ": Ridge - ROC AUC Score = 0.8761802854403709\n",
      "\n",
      "--> Fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.894070636426787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8943696958642415\n",
      ": CB - ROC AUC Score = 0.8923963686506299\n",
      ": Ridge - ROC AUC Score = 0.873680243840537\n",
      "\n",
      "--> Fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": XGB - ROC AUC Score = 0.8944077382563806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": LGB - ROC AUC Score = 0.8958117194942317\n",
      ": CB - ROC AUC Score = 0.893722748560412\n",
      ": Ridge - ROC AUC Score = 0.8762643441471586\n",
      "\n",
      "--> Overall metrics\n",
      ": XGB - ROC AUC Score = 0.8959058932774282\n",
      ": LGB - ROC AUC Score = 0.8969254992537874\n",
      ": CB - ROC AUC Score = 0.8948060924258656\n",
      ": Ridge - ROC AUC Score = 0.8754986716769508\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "random_state = 2021\n",
    "n_folds = 10\n",
    "k_fold = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "xgb_train_preds = np.zeros(train.shape[0], )\n",
    "xgb_test_preds = np.zeros(test.shape[0], )\n",
    "xgb_features = xgb_cat_features + cont_features\n",
    "\n",
    "lgb_train_preds = np.zeros(train.shape[0], )\n",
    "lgb_test_preds = np.zeros(test.shape[0], )\n",
    "lgb_features = lgb_cat_features + cont_features\n",
    "\n",
    "cb_train_preds = np.zeros(train.shape[0], )\n",
    "cb_test_preds = np.zeros(test.shape[0], )\n",
    "cb_features = cb_cat_features + cont_features\n",
    "\n",
    "ridge_train_preds = np.zeros(train.shape[0], )\n",
    "ridge_test_preds = np.zeros(test.shape[0], )\n",
    "ridge_features = ridge_cat_features + cont_features\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(k_fold.split(train, target)):\n",
    "    print(\"--> Fold {}\".format(fold + 1))\n",
    "    y_train = target.iloc[train_idx]\n",
    "    y_valid = target.iloc[test_idx]\n",
    "    \n",
    "    lgb_X_train, lgb_X_valid = train[lgb_features].iloc[train_idx], train[lgb_features].iloc[test_idx]\n",
    "    xgb_X_train, xgb_X_valid = train[xgb_features].iloc[train_idx], train[xgb_features].iloc[test_idx]\n",
    "    cb_X_train, cb_X_valid = train[cb_features].iloc[train_idx], train[cb_features].iloc[test_idx]\n",
    "    ridge_X_train, ridge_X_valid = train[ridge_features].iloc[train_idx], train[ridge_features].iloc[test_idx]\n",
    "    \n",
    "    xgb_model = XGBClassifier(\n",
    "        seed=random_state,\n",
    "        n_estimators=10000,\n",
    "        verbosity=1,\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"gpu_hist\",\n",
    "        gpu_id=0,\n",
    "        alpha=9.037672745139417,\n",
    "        colsample_bytree=0.6204453741210664,\n",
    "        gamma=0.7655610995827371,\n",
    "        reg_lambda=6.854931929134254,\n",
    "        learning_rate=0.013401479391378243,\n",
    "        max_bin=304,\n",
    "        max_depth=14,\n",
    "        min_child_weight=1.5513425169835457,\n",
    "        subsample=0.8303017072175757,\n",
    "    )\n",
    "    xgb_model.fit(\n",
    "        xgb_X_train,\n",
    "        y_train,\n",
    "        eval_set=[(xgb_X_valid, y_valid)], \n",
    "        verbose=0,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "    \n",
    "    train_oof_preds = xgb_model.predict_proba(xgb_X_valid)[:,1]\n",
    "    test_oof_preds = xgb_model.predict_proba(test[xgb_features])[:,1]\n",
    "    xgb_train_preds[test_idx] = train_oof_preds\n",
    "    xgb_test_preds += test_oof_preds / n_folds\n",
    "    print(\": XGB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n",
    "\n",
    "\n",
    "    lgb_model = LGBMClassifier(\n",
    "        cat_feature=[x for x in range(len(lgb_cat_features))],\n",
    "        random_state=random_state,\n",
    "        cat_l2=25.999876242730252,\n",
    "        cat_smooth=89.2699690675538,\n",
    "        colsample_bytree=0.2557260109926193,\n",
    "        early_stopping_round=200,\n",
    "        learning_rate=0.00918685483594994,\n",
    "        max_bin=788,\n",
    "        max_depth=81,\n",
    "        metric=\"auc\",\n",
    "        min_child_samples=292,\n",
    "        min_data_per_group=177,\n",
    "        n_estimators=1600000,\n",
    "        n_jobs=-1,\n",
    "        num_leaves=171,\n",
    "        reg_alpha=0.7115353581785044,\n",
    "        reg_lambda=5.658115293998945,\n",
    "        subsample=0.9262904583735796,\n",
    "        subsample_freq=1,\n",
    "        verbose=-1,\n",
    "    )\n",
    "    lgb_model.fit(\n",
    "        lgb_X_train,\n",
    "        y_train,\n",
    "        eval_set=[(lgb_X_valid, y_valid)], \n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    train_oof_preds = lgb_model.predict_proba(lgb_X_valid)[:,1]\n",
    "    test_oof_preds = lgb_model.predict_proba(test[lgb_features])[:,1]\n",
    "    lgb_train_preds[test_idx] = train_oof_preds\n",
    "    lgb_test_preds += test_oof_preds / n_folds\n",
    "    print(\": LGB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n",
    "    \n",
    "    \n",
    "    cb_model = CatBoostClassifier(\n",
    "        verbose=0,\n",
    "        eval_metric=\"AUC\",\n",
    "        loss_function=\"Logloss\",\n",
    "        random_state=random_state,\n",
    "        num_boost_round=20000,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=200,\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "        cat_features=[x for x in range(len(cb_cat_features))],\n",
    "        bagging_temperature=1.288692494969795,\n",
    "        grow_policy=\"Depthwise\",\n",
    "        l2_leaf_reg=9.847870133539244,\n",
    "        learning_rate=0.01877982653902465,\n",
    "        max_depth=8,\n",
    "        min_data_in_leaf=1,\n",
    "        penalties_coefficient=2.1176668909602734,\n",
    "    )\n",
    "    cb_model.fit(\n",
    "        cb_X_train,\n",
    "        y_train,\n",
    "        eval_set=[(cb_X_valid, y_valid)], \n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    train_oof_preds = cb_model.predict_proba(cb_X_valid)[:,1]\n",
    "    test_oof_preds = cb_model.predict_proba(test[cb_features])[:,1]\n",
    "    cb_train_preds[test_idx] = train_oof_preds\n",
    "    cb_test_preds += test_oof_preds / n_folds\n",
    "    print(\": CB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n",
    "\n",
    "    \n",
    "    ridge_model = RidgeClassifier(\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    ridge_model.fit(\n",
    "        ridge_X_train,\n",
    "        y_train,\n",
    "    )\n",
    "\n",
    "    train_oof_preds = ridge_model.decision_function(ridge_X_valid)\n",
    "    test_oof_preds = ridge_model.decision_function(test[ridge_features])\n",
    "    ridge_train_preds[test_idx] = train_oof_preds\n",
    "    ridge_test_preds += test_oof_preds / n_folds\n",
    "    print(\": Ridge - ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"--> Overall metrics\")\n",
    "print(\": XGB - ROC AUC Score = {}\".format(roc_auc_score(target, xgb_train_preds, average=\"micro\")))\n",
    "print(\": LGB - ROC AUC Score = {}\".format(roc_auc_score(target, lgb_train_preds, average=\"micro\")))\n",
    "print(\": CB - ROC AUC Score = {}\".format(roc_auc_score(target, cb_train_preds, average=\"micro\")))\n",
    "print(\": Ridge - ROC AUC Score = {}\".format(roc_auc_score(target, ridge_train_preds, average=\"micro\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2021\n",
    "n_folds = 10\n",
    "k_fold = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "l1_train = pd.DataFrame(data={\n",
    "    \"xgb\": xgb_train_preds.tolist(),\n",
    "    \"lgb\": lgb_train_preds.tolist(),\n",
    "    \"cb\": cb_train_preds.tolist(),\n",
    "    \"ridge\": ridge_train_preds.tolist(),\n",
    "    \"target\": target.tolist()\n",
    "})\n",
    "l1_test = pd.DataFrame(data={\n",
    "    \"xgb\": xgb_test_preds.tolist(),\n",
    "    \"lgb\": lgb_test_preds.tolist(),\n",
    "    \"cb\": cb_test_preds.tolist(),\n",
    "    \"ridge\": ridge_test_preds.tolist(),    \n",
    "})\n",
    "\n",
    "train_preds = np.zeros(len(l1_train.index), )\n",
    "test_preds = np.zeros(len(l1_test.index), )\n",
    "features = [\"xgb\", \"lgb\", \"cb\", \"ridge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Fold 1\n",
      ": ROC AUC Score = 0.899600387087311\n",
      "\n",
      "--> Fold 2\n",
      ": ROC AUC Score = 0.8970327015324786\n",
      "\n",
      "--> Fold 3\n",
      ": ROC AUC Score = 0.8959350137322821\n",
      "\n",
      "--> Fold 4\n",
      ": ROC AUC Score = 0.8955916924138633\n",
      "\n",
      "--> Fold 5\n",
      ": ROC AUC Score = 0.8974905622017265\n",
      "\n",
      "--> Fold 6\n",
      ": ROC AUC Score = 0.8985930947562503\n",
      "\n",
      "--> Fold 7\n",
      ": ROC AUC Score = 0.8992157740818357\n",
      "\n",
      "--> Fold 8\n",
      ": ROC AUC Score = 0.8985173933299797\n",
      "\n",
      "--> Fold 9\n",
      ": ROC AUC Score = 0.8949465069503907\n",
      "\n",
      "--> Fold 10\n",
      ": ROC AUC Score = 0.8960272166774221\n",
      "\n",
      "--> Overall metrics\n",
      ": ROC AUC Score = 0.8972760782048211\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(k_fold.split(l1_train, target)):\n",
    "    print(\"--> Fold {}\".format(fold + 1))\n",
    "    y_train = target.iloc[train_index]\n",
    "    y_valid = target.iloc[test_index]\n",
    "\n",
    "    x_train = pd.DataFrame(l1_train[features].iloc[train_index])\n",
    "    x_valid = pd.DataFrame(l1_train[features].iloc[test_index])\n",
    "    \n",
    "    model = RidgeClassifier(\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "    )\n",
    "\n",
    "    train_oof_preds = model.decision_function(x_valid)\n",
    "    test_oof_preds = model.decision_function(l1_test[features])\n",
    "    train_preds[test_index] = train_oof_preds\n",
    "    test_preds += test_oof_preds / n_folds\n",
    "    print(\": ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds, average=\"micro\")))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"--> Overall metrics\")\n",
    "print(\": ROC AUC Score = {}\".format(roc_auc_score(target, train_preds, average=\"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "# submission[\"target\"] = test_preds.tolist()\n",
    "# submission.to_csv(\"ensemble_model_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = test_preds\n",
    "submission.to_csv('model_cv_4_test_roc.csv', index = False)\n",
    "\n",
    "sub2 = pd.DataFrame({'target' : train_preds})\n",
    "sub2.to_csv('model_cv_4_train_roc.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
